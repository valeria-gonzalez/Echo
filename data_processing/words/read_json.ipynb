{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is made to extract the relevant information from the words provided by the JSONL dump obtained from [WikiExtract](https://github.com/tatuylonen/wiktextract) and saves the words to JSON files.\n",
    "\n",
    "The necessary information for a word is:\n",
    "\n",
    "- Word in english \n",
    "- Part of speech (adjective, noun, etc.)\n",
    "  - Definition for the word as the part of speech\n",
    "- Audio file of the word's pronunciation\n",
    "- Spanish translation(s) of the word\n",
    "- IPA pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_word_dict(word_dict: dict):\n",
    "    \"\"\"Print information from word dictionary.\"\"\"\n",
    "    for word, attributes in word_dict.items():\n",
    "        print(f\"\\n-------------- {word} -------------\")\n",
    "        for attribute, value in attributes.items():\n",
    "            print(f\"{attribute}:\")\n",
    "            if attribute == \"definitions\":\n",
    "                for pos, glosses in value.items():\n",
    "                    print(f\"   {pos}\")\n",
    "                    for gloss in glosses:\n",
    "                        print(f\"     - {gloss}\")\n",
    "            else:\n",
    "                print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract word from json\n",
    "\n",
    "This function takes a json object extracted when reading a non-empty line from the JSONL file and creates a dictionary with all the relevant information for a word.\n",
    "\n",
    "The final dictionary has the following structure:\n",
    "\n",
    "```\n",
    "word_obj = {\n",
    "        \"word\": word,\n",
    "        \"pos\" : part_of_speech,\n",
    "        \"definitions\" : unique_definitions,\n",
    "        \"ipa\": ipa,\n",
    "        \"mp3_url\" : mp3_url,\n",
    "        \"translation\" : spanish_translation,\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_from_json(obj:dict)->dict:\n",
    "    \"\"\" Extracts the relevant keys for a word from a JSON object. Returns a \n",
    "    dictionary. \"\"\"\n",
    "    \n",
    "    # Check that the word is in english\n",
    "    language = obj.get(\"lang\")\n",
    "    \n",
    "    if language != \"English\":\n",
    "        return None\n",
    "    \n",
    "    # Retrieve significant keys\n",
    "    word = obj.get(\"word\")\n",
    "    part_of_speech = obj.get(\"pos\")\n",
    "    senses = obj.get(\"senses\")\n",
    "    sounds = obj.get(\"sounds\")\n",
    "    translations = obj.get(\"translations\")\n",
    "    \n",
    "    # Needed variables\n",
    "    unique_definitions = None\n",
    "    ipa = None\n",
    "    mp3_url = None\n",
    "    spanish_translation = None\n",
    "    \n",
    "    # Definitions \n",
    "    # {senses: {glosses: x}}\n",
    "    if senses:\n",
    "        definitions = list() # Save all definitions for the word\n",
    "        for item in senses:\n",
    "            if item.get(\"glosses\"):\n",
    "                definitions += item[\"glosses\"]\n",
    "\n",
    "        # Eliminate duplicate definitions\n",
    "        unique_definitions = list(set(definitions))\n",
    "                         \n",
    "    # Audio file and IPA pronunciation \n",
    "    # {sounds: {ipa: x, mp3_url: x}}\n",
    "    if sounds:\n",
    "        for item in sounds:\n",
    "            if ipa and mp3_url:\n",
    "                break\n",
    "            \n",
    "            if ipa == None and item.get(\"ipa\"):\n",
    "                ipa = item[\"ipa\"]\n",
    "                \n",
    "            if mp3_url == None and item.get(\"mp3_url\"):\n",
    "                mp3_url = item[\"mp3_url\"]\n",
    "    \n",
    "    # Spanish translation\n",
    "    # {translation: {lang: x, word: x}}\n",
    "    if translations:\n",
    "        for item in translations:\n",
    "            if spanish_translation:\n",
    "                break\n",
    "            \n",
    "            if item.get(\"lang\") and item.get(\"word\"):\n",
    "                if(item[\"lang\"] == \"Spanish\"):\n",
    "                    spanish_translation = item[\"word\"]\n",
    "                    \n",
    "    # Add information to dictionary\n",
    "    word_obj = {\n",
    "        \"word\": word,\n",
    "        \"pos\" : part_of_speech,\n",
    "        \"definitions\" : unique_definitions,\n",
    "        \"ipa\": ipa,\n",
    "        \"mp3_url\" : mp3_url,\n",
    "        \"translation\" : spanish_translation,\n",
    "    }\n",
    "    \n",
    "    return word_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add an extracted word to an accumulated words dictionary \n",
    "\n",
    "The JSONL dump provides multiple entries for the same word, distinguishing each by their role in the part of speech (noun, adjective, verb, etc).\n",
    "\n",
    "To avoid having multiple entries of the same word, this function groups different entries for the same word. For every different part of speech, its corresponding definitions are saved under it.\n",
    "\n",
    "The structure for the final dictionary is as follows:\n",
    "\n",
    "```\n",
    "word_dict = {\n",
    "    word: {\n",
    "        \"definitions\": {\n",
    "            part_of_speech: [list of definitions]\n",
    "        },\n",
    "        \"ipa\": ipa,\n",
    "        \"mp3_url\": mp3_url,\n",
    "        \"translations\": [list of translations],\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_to_dict(word_obj:dict, word_dict:dict)->None:\n",
    "    \"\"\"\n",
    "    Add an extracted word to a dictonary.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract keys\n",
    "    word = word_obj[\"word\"]\n",
    "    part_of_speech = word_obj[\"pos\"]\n",
    "    definitions = word_obj[\"definitions\"]\n",
    "    ipa = word_obj[\"ipa\"]\n",
    "    mp3_url = word_obj[\"mp3_url\"]\n",
    "    translation = word_obj[\"translation\"]\n",
    "\n",
    "    # Insert a new entry\n",
    "    if word not in word_dict:\n",
    "        word_dict[word] = {\n",
    "            \"definitions\": {part_of_speech: definitions},\n",
    "            \"ipa\": ipa,\n",
    "            \"mp3_url\": mp3_url,\n",
    "            \"translations\": [translation] if translation else None,\n",
    "        }\n",
    "        \n",
    "    # Update an existing entry\n",
    "    else:\n",
    "        # Add translation\n",
    "        if translation:\n",
    "            if word_dict[word][\"translations\"] == None:\n",
    "                word_dict[word][\"translations\"] = list()\n",
    "                \n",
    "            word_dict[word][\"translations\"].append(translation)\n",
    "        \n",
    "        # Add definitions for a new part of speech\n",
    "        if part_of_speech and part_of_speech not in word_dict[word][\"definitions\"]:\n",
    "            word_dict[word][\"definitions\"][part_of_speech] = definitions\n",
    "        \n",
    "        # Update information on empty keys\n",
    "        for key in [\"ipa\", \"mp3_url\"]:\n",
    "            if not word_dict[word][key] and word_obj[key]:\n",
    "                word_dict[word][key] = word_obj[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write the accumulated words dictionary to JSON file\n",
    "\n",
    "This functions writes the accumulated words without repetition to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_json(word_dict:dict)->None:\n",
    "    \"\"\" \n",
    "    Write a dictionary to a JSON file. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Unique file name\n",
    "    filename = f\"datasets/word_files/words-{uuid.uuid4().hex}.json\"\n",
    "\n",
    "    # Serializing json\n",
    "    json_object = json.dumps(word_dict, indent=4)\n",
    " \n",
    "    # Writing to sample.json\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Eliminate words with empty values from the accumulated words dictionary\n",
    "\n",
    "This function takes the accumulated words dictionaries and eliminates all words that are missing any field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_word_dict(word_dict:dict)->None:\n",
    "    \"\"\" \n",
    "    Eliminate words that have empty keys from the dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    incomplete_words = list()\n",
    "    \n",
    "    # Save words with incomplete fields\n",
    "    for word, info in word_dict.items():\n",
    "        if None in info.values():\n",
    "            incomplete_words.append(word)\n",
    "          \n",
    "    # Eliminate words from dictionary  \n",
    "    for word in incomplete_words:\n",
    "        word_dict.pop(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read JSONL dump and create JSON files with words\n",
    "\n",
    "This is the driver function for all the above functions. \n",
    "\n",
    "This function:\n",
    "1. Reads the JSONL dump line by line until the specified amount of words has been reached.\n",
    "2. Extracts the pertinent word information.\n",
    "3. Adds the word to an accumulated words dictionary.\n",
    "4. Once the amount of words reaches the specified 'words per JSON' limit, it saves the dictionary to a JSON file.\n",
    "5. Returns the amount of words saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words_from_file(filename:str, max_words:int=-1, \n",
    "                            batch_size:int=100)->int:\n",
    "    \"\"\"\n",
    "    Extracts up to `max_words` entries from a JSONL file, saving them in \n",
    "    batches of `batch_size` entries per output JSON file.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of words successfully saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    word_dict = defaultdict(lambda: None) # Dictionary to save resulting words\n",
    "    word_count = 0\n",
    "    \n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # Read max num of words\n",
    "            if max_words != -1 and word_count >= max_words: \n",
    "                break\n",
    "            \n",
    "            if line.strip(): \n",
    "                try:\n",
    "                    obj = json.loads(line) # Read line as json object\n",
    "                    word_obj = get_word_from_json(obj) \n",
    "                    \n",
    "                    if word_obj != None: \n",
    "                        word = word_obj[\"word\"]\n",
    "                        \n",
    "                        # Save dictionary to json file\n",
    "                        # Check that there's no new info for existing word\n",
    "                        if word not in word_dict and len(word_dict) >= batch_size:\n",
    "                            prune_word_dict(word_dict) \n",
    "                            \n",
    "                            # Check if still enough words\n",
    "                            if len(word_dict) >= batch_size:\n",
    "                                dict_to_json(word_dict)\n",
    "                                word_count += len(word_dict)\n",
    "                                word_dict.clear()\n",
    "                        \n",
    "                        add_word_to_dict(word_obj, word_dict)\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding line {i + 1}: {e}\")\n",
    "                    print(f\"Line content: {line[:200]}\")\n",
    "                    continue\n",
    "    \n",
    "    # Check for remaining words          \n",
    "    if(len(word_dict)):\n",
    "        prune_word_dict(word_dict)\n",
    "        \n",
    "        if(len(word_dict) > 0):\n",
    "            dict_to_json(word_dict)\n",
    "            word_count += len(word_dict)\n",
    "            word_dict.clear()\n",
    "        \n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Call function\n",
    "\n",
    "The call to the function should include the file from which to extract the words, as well as the maximum number of words to read and the amount of words to save per JSON. If no max_words is specified, it'll read the whole file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'datasets/raw-wiktextract-data.jsonl' # Determine filename\n",
    "count = process_words_from_file(filename, max_words=10000, batch_size=2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 words.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saved {count} words.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
