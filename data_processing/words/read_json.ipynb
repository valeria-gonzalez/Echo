{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is made to extract the relevant information about words from the JSONL file provided.\n",
    "The final features to be obtained will be:\n",
    "- English word \n",
    "- Type of word (adjective, noun, etc.)\n",
    "  - Definition\n",
    "- Audio file\n",
    "- Spanish translation\n",
    "- IPA pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(word_dict: dict):\n",
    "    for word, attributes in word_dict.items():\n",
    "        print(f\"\\n-------------- {word} -------------\")\n",
    "        for attribute, value in attributes.items():\n",
    "            print(f\"{attribute}:\")\n",
    "            if attribute == \"definitions\":\n",
    "                for pos, glosses in value.items():\n",
    "                    print(f\"   {pos}\")\n",
    "                    for gloss in glosses:\n",
    "                        print(f\"     - {gloss}\")\n",
    "            else:\n",
    "                print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_from_json(obj:dict)->dict:\n",
    "    \"\"\" Extract relevant keys for a word from a JSON object. \"\"\"\n",
    "    \n",
    "    # Check that the word is in english\n",
    "    language = obj.get(\"lang\")\n",
    "    \n",
    "    if language != \"English\":\n",
    "        return None\n",
    "    \n",
    "    # Retrieve significant keys\n",
    "    word = obj.get(\"word\")\n",
    "    part_of_speech = obj.get(\"pos\")\n",
    "    senses = obj.get(\"senses\")\n",
    "    sounds = obj.get(\"sounds\")\n",
    "    translations = obj.get(\"translations\")\n",
    "    \n",
    "    # Needed variables\n",
    "    unique_definitions = None\n",
    "    ipa = None\n",
    "    mp3_url = None\n",
    "    spanish_translation = None\n",
    "    \n",
    "    # Definitions \n",
    "    # {senses: {glosses: x}}\n",
    "    if senses:\n",
    "        definitions = list() # Save all definitions for the word\n",
    "        for item in senses:\n",
    "            if item.get(\"glosses\"):\n",
    "                definitions += item[\"glosses\"]\n",
    "\n",
    "        # Eliminate duplicate definitions\n",
    "        unique_definitions = list(set(definitions))\n",
    "                         \n",
    "    # Audio file and IPA pronunciation \n",
    "    # {sounds: {ipa: x, mp3_url: x}}\n",
    "    if sounds:\n",
    "        for item in sounds:\n",
    "            if ipa and mp3_url:\n",
    "                break\n",
    "            \n",
    "            if ipa == None and item.get(\"ipa\"):\n",
    "                ipa = item[\"ipa\"]\n",
    "                \n",
    "            if mp3_url == None and item.get(\"mp3_url\"):\n",
    "                mp3_url = item[\"mp3_url\"]\n",
    "    \n",
    "    # Spanish translation\n",
    "    # {translation: {lang: x, word: x}}\n",
    "    if translations:\n",
    "        for item in translations:\n",
    "            if spanish_translation:\n",
    "                break\n",
    "            \n",
    "            if item.get(\"lang\") and item.get(\"word\"):\n",
    "                if(item[\"lang\"] == \"Spanish\"):\n",
    "                    spanish_translation = item[\"word\"]\n",
    "                    \n",
    "    # Add information to dictionary\n",
    "    word_obj = {\n",
    "        \"word\": word,\n",
    "        \"pos\" : part_of_speech,\n",
    "        \"definitions\" : unique_definitions,\n",
    "        \"ipa\": ipa,\n",
    "        \"mp3_url\" : mp3_url,\n",
    "        \"translation\" : spanish_translation,\n",
    "    }\n",
    "    \n",
    "    return word_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_to_dict(word_obj:dict, word_dict:dict)->None:\n",
    "    \"\"\"Add an extracted word to a dictonary.\"\"\"\n",
    "    \n",
    "    # Extract keys\n",
    "    word = word_obj[\"word\"]\n",
    "    part_of_speech = word_obj[\"pos\"]\n",
    "    definitions = word_obj[\"definitions\"]\n",
    "    ipa = word_obj[\"ipa\"]\n",
    "    mp3_url = word_obj[\"mp3_url\"]\n",
    "    translation = word_obj[\"translation\"]\n",
    "\n",
    "    # Insert a new entry\n",
    "    if word not in word_dict:\n",
    "        word_dict[word] = {\n",
    "            \"definitions\": {part_of_speech: definitions},\n",
    "            \"ipa\": ipa,\n",
    "            \"mp3_url\": mp3_url,\n",
    "            \"translations\": [translation] if translation else None,\n",
    "        }\n",
    "        \n",
    "    # Update an existing entry\n",
    "    else:\n",
    "        # Add translation\n",
    "        if translation:\n",
    "            if word_dict[word][\"translations\"] == None:\n",
    "                word_dict[word][\"translations\"] = list()\n",
    "                \n",
    "            word_dict[word][\"translations\"].append(translation)\n",
    "        \n",
    "        # Add definitions for a new part of speech\n",
    "        if part_of_speech and part_of_speech not in word_dict[word][\"definitions\"]:\n",
    "            word_dict[word][\"definitions\"][part_of_speech] = definitions\n",
    "        \n",
    "        # Update information on empty keys\n",
    "        for key in [\"ipa\", \"mp3_url\"]:\n",
    "            if not word_dict[word][key] and word_obj[key]:\n",
    "                word_dict[word][key] = word_obj[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_json(word_dict:dict)->None:\n",
    "    \"\"\" Write dictionary to a JSON file. \"\"\"\n",
    "    \n",
    "    # Unique file name\n",
    "    filename = f\"datasets/word_files/words-{uuid.uuid4().hex}.json\"\n",
    "\n",
    "    # Serializing json\n",
    "    json_object = json.dumps(word_dict, indent=4)\n",
    " \n",
    "    # Writing to sample.json\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_word_dict(word_dict:dict):\n",
    "    \"\"\" Eliminate words that have empty keys.\"\"\"\n",
    "    \n",
    "    incomplete_words = list()\n",
    "    \n",
    "    for word, info in word_dict.items():\n",
    "        if None in info.values():\n",
    "            incomplete_words.append(word)\n",
    "            \n",
    "    for word in incomplete_words:\n",
    "        word_dict.pop(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words_from_file(filename:str, max_words:int=-1, \n",
    "                            batch_size:int=100)->int:\n",
    "    \"\"\" Extracts a specified amount of words (max_words) from JSONL file dump \n",
    "    and saves them to one or more JSON files with at most batch_size words.\"\"\"\n",
    "    \n",
    "    word_dict = defaultdict(lambda: None) # Dictionary to save resulting words\n",
    "    word_count = 0\n",
    "    \n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        # Read file line by line\n",
    "        for i, line in enumerate(f):\n",
    "            # Read max num of words\n",
    "            if max_words != -1 and word_count >= max_words:\n",
    "                break\n",
    "\n",
    "            # Skip empty lines\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                word_obj = get_word_from_json(obj)\n",
    "                \n",
    "                if word_obj == None:\n",
    "                    continue\n",
    "                \n",
    "                word = word_obj[\"word\"]\n",
    "                \n",
    "                # Save dictionary to json file\n",
    "                # Check that there's no new info for existing word\n",
    "                if word not in word_dict and len(word_dict) >= batch_size:\n",
    "                    prune_word_dict(word_dict) # Delete incomplete words\n",
    "                    \n",
    "                    if len(word_dict) >= batch_size:\n",
    "                        dict_to_json(word_dict)\n",
    "                        word_count += len(word_dict)\n",
    "                        word_dict.clear()\n",
    "                \n",
    "                add_word_to_dict(word_obj, word_dict)\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding line {i + 1}: {e}\")\n",
    "                print(f\"Line content: {line[:200]}\")\n",
    "    \n",
    "    # Check for remaining words          \n",
    "    if(len(word_dict)):\n",
    "        prune_word_dict(word_dict)\n",
    "        \n",
    "        if(len(word_dict) > 0):\n",
    "            dict_to_json(word_dict)\n",
    "            word_count += len(word_dict)\n",
    "            word_dict.clear()\n",
    "        \n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'datasets/raw-wiktextract-data.jsonl' # Determine filename\n",
    "count = process_words_from_file(filename, max_words=10000, batch_size=2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 words.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saved {count} words.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
