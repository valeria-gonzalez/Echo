{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is made to extract the relevant information about words from the JSONL file provided.\n",
    "The final features to be obtained will be:\n",
    "- English word \n",
    "- Type of word (adjective, noun, etc.)\n",
    "  - Definition\n",
    "- Audio file\n",
    "- Spanish translation\n",
    "- IPA pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_object(obj):\n",
    "    \"\"\" Extract relevant keys from JSON object. \"\"\"\n",
    "    \n",
    "    # Retrieve significant keys\n",
    "    word = obj.get(\"word\")\n",
    "    pos = obj.get(\"pos\")\n",
    "    senses = obj.get(\"senses\")\n",
    "    sounds = obj.get(\"sounds\")\n",
    "    translations = obj.get(\"translations\")\n",
    "    \n",
    "    # Needed variables\n",
    "    unique_definitions = None\n",
    "    ipa = None\n",
    "    mp3_url = None\n",
    "    spanish_translation = None\n",
    "    \n",
    "    # Definitions\n",
    "    if senses:\n",
    "        definitions = list() # Save all definitions for the word\n",
    "        for item in senses:\n",
    "            if item.get('glosses'):\n",
    "                definitions += item[\"glosses\"]\n",
    "\n",
    "        # Eliminate duplicate definitions\n",
    "        unique_definitions = list(set(definitions))\n",
    "                         \n",
    "    # Audio file and IPA pronunciation\n",
    "    if sounds:\n",
    "        for item in sounds:\n",
    "            if ipa and mp3_url:\n",
    "                break\n",
    "            \n",
    "            if ipa == None and item.get('ipa'):\n",
    "                ipa = item[\"ipa\"]\n",
    "                \n",
    "            if mp3_url == None and item.get('mp3_url'):\n",
    "                mp3_url = item[\"mp3_url\"]\n",
    "    \n",
    "    # Spanish translation\n",
    "    if translations:\n",
    "        for item in translations:\n",
    "            if spanish_translation:\n",
    "                break\n",
    "            \n",
    "            if spanish_translation == None and item.get('lang'):\n",
    "                if(item[\"lang\"] == \"Spanish\"):\n",
    "                    spanish_translation = item[\"word\"]\n",
    "                    \n",
    "    # Add information to dictionary\n",
    "    word_obj = {\n",
    "        \"word\": word,\n",
    "        \"pos\" : pos,\n",
    "        \"definitions\" : unique_definitions,\n",
    "        \"ipa\": ipa,\n",
    "        \"mp3_url\" : mp3_url,\n",
    "        \"translation\" : spanish_translation,\n",
    "    }\n",
    "    \n",
    "    return word_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words_from_file(filename, word_dict, max_items=5):\n",
    "    \"\"\" Extract word object and add it to a dictionary. \"\"\"\n",
    "    \n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= max_items:\n",
    "                break\n",
    "\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                word_obj = read_json_object(obj) # Retrieve object\n",
    "\n",
    "                # Extract keys\n",
    "                word = word_obj[\"word\"]\n",
    "                pos = word_obj[\"pos\"]\n",
    "                definitions = word_obj[\"definitions\"]\n",
    "                ipa = word_obj[\"ipa\"]\n",
    "                mp3_url = word_obj[\"mp3_url\"]\n",
    "                translation = word_obj[\"translation\"]\n",
    "\n",
    "                # Update dictionary\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = {\n",
    "                        \"definitions\": {pos: definitions},\n",
    "                        \"ipa\": ipa,\n",
    "                        \"mp3_url\": mp3_url,\n",
    "                        \"translation\": translation,\n",
    "                    }\n",
    "                else:\n",
    "                    if pos not in word_dict[word][\"definitions\"]:\n",
    "                        word_dict[word][\"definitions\"][pos] = definitions\n",
    "\n",
    "                    for key in [\"ipa\", \"mp3_url\", \"translation\"]:\n",
    "                        if not word_dict[word][key] and word_obj[key]:\n",
    "                            word_dict[word][key] = word_obj[key]\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding line {i + 1}: {e}\")\n",
    "                print(f\"Line content: {line[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'datasets/raw-wiktextract-data.jsonl' # Determine filename\n",
    "word_dict = defaultdict(lambda: None)\n",
    "\n",
    "process_words_from_file(filename, word_dict, 3) # Dictionary to save resulting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------- dictionary -------------\n",
      "definitions:\n",
      "   noun\n",
      "     - An associative array, a data structure where each value is referenced by a particular key, analogous to words and definitions in a dictionary (sense 1).\n",
      "     - A synchronic dictionary of a standardised language held to only contain words that are properly part of the language.\n",
      "     - A reference work with a list of words from one or more languages, normally ordered alphabetically, explaining each word's meanings (senses), and sometimes also containing information on its etymology, pronunciation, usage, semantic relations, and translations, as well as other data.\n",
      "     - Any work that has a list of material organized alphabetically; e.g., biographical dictionary, encyclopedic dictionary.\n",
      "   verb\n",
      "     - To add to a dictionary.\n",
      "     - To compile a dictionary.\n",
      "     - To look up in a dictionary.\n",
      "ipa:\n",
      "/ˈdɪk.ʃə.nə.ɹi/\n",
      "mp3_url:\n",
      "https://upload.wikimedia.org/wikipedia/commons/transcoded/1/1f/En-uk-dictionary.ogg/En-uk-dictionary.ogg.mp3\n",
      "translation:\n",
      "diccionario\n",
      "\n",
      "-------------- free -------------\n",
      "definitions:\n",
      "   adj\n",
      "     - With no or only freedom-preserving limitations on distribution or modification.\n",
      "     - Unconstrained.\n",
      "     - Privileged or individual; proprietary.\n",
      "     - Such that any map f from X to the underlying set of an object A in the same category as F induces a map ̄f from F to A which is compatible with f (i.e. such that f=̄f∘i).\n",
      "     - Unconstrained by quantifiers.\n",
      "     - Without; not containing (what is specified); exempt; clear; liberated.\n",
      "     - Not imprisoned or enslaved.\n",
      "     - Obtainable without any payment.\n",
      "     - Without obligations.\n",
      "     - Complimentary.\n",
      "     - Invested with a particular freedom or franchise; enjoying certain immunities or privileges; admitted to special rights; followed by of.\n",
      "     - Having a linearly independent set of generators (called a basis).\n",
      "     - Ready; eager; acting without spurring or whipping; spirited.\n",
      "     - Generous; liberal.\n",
      "     - Certain or honourable; the opposite of base.\n",
      "     - Unattached or uncombined.\n",
      "     - To be enjoyed by anyone freely.\n",
      "     - Unobstructed, without blockages.\n",
      "     - Of a rocket or missile: not under the control of a guidance system after being launched.\n",
      "     - Not attached; loose.\n",
      "     - In any of various technical senses generic, universal.\n",
      "     - Unconstrained of identifiers, not bound.\n",
      "     - Intended for release, as opposed to a checked version.\n",
      "     - Clear of offence or crime; guiltless; innocent.\n",
      "     - Not currently in use; not taken; unoccupied.\n",
      "     - Having a set of generators which satisfy no non-trivial relations; equivalently, being the group of reduced words on a set of generators.\n",
      "     - (of a morpheme) That can be used by itself, unattached to another morpheme.\n",
      "     - Upholding individual rights.\n",
      "ipa:\n",
      "/fɹiː/\n",
      "mp3_url:\n",
      "https://upload.wikimedia.org/wikipedia/commons/transcoded/c/c9/En-uk-free.ogg/En-uk-free.ogg.mp3\n",
      "translation:\n",
      "libre\n"
     ]
    }
   ],
   "source": [
    "for word, attributes in word_dict.items():\n",
    "    print(f\"\\n-------------- {word} -------------\")\n",
    "    for attribute, value in attributes.items():\n",
    "        print(f\"{attribute}:\")\n",
    "        if attribute == \"definitions\":\n",
    "            for pos, glosses in value.items():\n",
    "                print(f\"   {pos}\")\n",
    "                for gloss in glosses:\n",
    "                    print(f\"     - {gloss}\")\n",
    "        else:\n",
    "            print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
